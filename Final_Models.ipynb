{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "simplified-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from   category_encoders       import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from   sklearn.compose         import *\n",
    "from   sklearn.experimental    import enable_iterative_imputer\n",
    "from   sklearn.impute          import *\n",
    "from   sklearn.metrics         import * \n",
    "from   sklearn.preprocessing   import *\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model  import Lasso, Ridge, ElasticNet, HuberRegressor, BayesianRidge\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-northwest",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cronisterct/.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "instant-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('NCAA_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-malta",
   "metadata": {},
   "source": [
    "# Splitting Data\n",
    "Split off 10% of data for test set and save for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "declared-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.sample(frac=.1, random_state=23)\n",
    "\n",
    "train = df[~df.index.isin(test.index)]\n",
    "\n",
    "X = train[['SCHOOL_TYPE',\n",
    "       'SPORT_CODE', 'NCAA_DIVISION', 'NCAA_SUBDIVISION',\n",
    "       'NCAA_CONFERENCE', 'FOURYEAR_ATHLETES',\n",
    "       'FOURYEAR_ELIGIBILITY']]\n",
    "y = train['FOURYEAR_RETENTION']\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-crime",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-infrared",
   "metadata": {},
   "source": [
    "While there are no missing values in this dataset, I wanted to include Simple Imputer in my pipeline for my deployment incase someone tries to pass data that is missing a value. I wanted to use a min max scaler on the continuous data so that it was consistent and to 'pull in' outliers. Additionally, I added a one hot encoder to my preprocessing pipeline so that the categorical variables could be properly transformed for my models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "undefined-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['NCAA_CONFERENCE','SCHOOL_TYPE','NCAA_SUBDIVISION', 'SPORT_CODE', 'NCAA_DIVISION']\n",
    "numerical_columns = ['FOURYEAR_ATHLETES', \n",
    "       'FOURYEAR_ELIGIBILITY']\n",
    "\n",
    "\n",
    "con_pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                      ('imputer', SimpleImputer(strategy='median', add_indicator=True))])\n",
    "\n",
    "cat_pipe = Pipeline([('ohe', OneHotEncoder(handle_unknown='ignore')),\n",
    "                     ('imputer', SimpleImputer(strategy='most_frequent', add_indicator=True))])\n",
    "\n",
    "preprocessing = ColumnTransformer([('categorical', cat_pipe,  categorical_columns),\n",
    "                                   ('continuous',  con_pipe, numerical_columns),\n",
    "                                   ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-courage",
   "metadata": {},
   "source": [
    "# Choose two algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-television",
   "metadata": {},
   "source": [
    "I began by picking 5 regressor algorithms we had seen in class and I wanted to pick two of them based off their MAE and MSE with no hyperparameter tuning.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "julian-subscription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression  - mean squared error: 0.00034345111120908354\n",
      "LinearRegression  - mean absolute error: 0.013441340393262004\n",
      "Lasso             - mean squared error: 0.0005989615192239207\n",
      "Lasso             - mean absolute error: 0.019115824457593678\n",
      "Ridge             - mean squared error: 0.0003436976780966718\n",
      "Ridge             - mean absolute error: 0.013491849504644673\n",
      "ElasticNet        - mean squared error: 0.0005989615192239207\n",
      "ElasticNet        - mean absolute error: 0.019115824457593678\n",
      "RandomForestRegressor - mean squared error: 0.0003692202145249629\n",
      "RandomForestRegressor - mean absolute error: 0.013576265726495724\n"
     ]
    }
   ],
   "source": [
    "algorithms = [LinearRegression(), Lasso(), Ridge(), ElasticNet(), \n",
    "               RandomForestRegressor()]\n",
    "\n",
    "for algo in algorithms:\n",
    "    pipe = Pipeline([('preprocessing', preprocessing), \n",
    "                     ('lm',     algo)])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_validation)\n",
    "    mse = mean_squared_error(y_validation, y_pred)\n",
    "    mae = mean_absolute_error(y_validation, y_pred)\n",
    "    print(f\"{algo.__class__.__name__:<17} - mean squared error: {mse}\")\n",
    "    print(f\"{algo.__class__.__name__:<17} - mean absolute error: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-grave",
   "metadata": {},
   "source": [
    "Choose Linear Regression and Random Forest Regressor as these give us the lowest MSE and MAE without hyperparameter tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-soundtrack",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-broadway",
   "metadata": {},
   "source": [
    "I first chose to tune a linear regression model using a random search cross validation as it is faster than a grid search while still finding optimal hyperparameters for the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abstract-wallet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  65 out of  65 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(transformers=[('categorical',\n",
       "                                                  Pipeline(steps=[('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore')),\n",
       "                                                                  ('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                                 strategy='most_frequent'))]),\n",
       "                                                  ['NCAA_CONFERENCE',\n",
       "                                                   'SCHOOL_TYPE',\n",
       "                                                   'NCAA_SUBDIVISION',\n",
       "                                                   'SPORT_CODE',\n",
       "                                                   'NCAA_DIVISION']),\n",
       "                                                 ('continuous',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   MinMaxScaler()),\n",
       "                                                                  ('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                                 strategy='median'))]),\n",
       "                                                  ['FOURYEAR_ATHLETES',\n",
       "                                                   'FOURYEAR_ELIGIBILITY'])])),\n",
       "                ('lr',\n",
       "                 RandomizedSearchCV(cv=5, estimator=LinearRegression(),\n",
       "                                    n_iter=13,\n",
       "                                    param_distributions={'copy_X': [True,\n",
       "                                                                    False],\n",
       "                                                         'fit_intercept': [True,\n",
       "                                                                           False],\n",
       "                                                         'n_jobs': [-1, 1],\n",
       "                                                         'normalize': [False,\n",
       "                                                                       True]},\n",
       "                                    random_state=23, verbose=1))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {'copy_X': [True, False],\n",
    " 'fit_intercept': [True, False],\n",
    " 'n_jobs': [-1,1],\n",
    " 'normalize': [False, True]}\n",
    "lr_rand = RandomizedSearchCV(estimator=LinearRegression(), \n",
    "                              param_distributions=hyperparameters, \n",
    "                              n_iter=13, \n",
    "                              cv=5, \n",
    "                              verbose=1,\n",
    "                              random_state=23)\n",
    "\n",
    "pipe_lr_cv = Pipeline([('preprocessing', preprocessing), \n",
    "                 ('lr', lr_rand)])\n",
    "\n",
    "\n",
    "pipe_lr_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-match",
   "metadata": {},
   "source": [
    "I then get the best model that came out of the cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "environmental-roommate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(n_jobs=-1, normalize=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_rand.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-artist",
   "metadata": {},
   "source": [
    "I then wanted to display the hyperparameters that were chosen out of the cross validation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "japanese-public",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_rand.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-patent",
   "metadata": {},
   "source": [
    "I then fit this model on the data to be absolutely clear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "artificial-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([('preprocessing', preprocessing), \n",
    "                ('lr', lr_rand.best_estimator_)])\n",
    "\n",
    "y_pred_lr = pipe_lr.predict(X_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-immune",
   "metadata": {},
   "source": [
    "I chose MAE and MSE as my test metrics because I think they give two different views of the performance of my model. While MAE gives me an idea of how off my predictions are, on average, in the scale of my y. This gives a clear and interpretable value. I also included MSE because it is another well known metric, but it also takes into account the magnitude that I am off -- i.e. I am penalized more for larger predictive mistakes. I think these metrics together give me a well rounded understanding of my models performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dependent-riverside",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.013442423500721015\n",
      "MSE 0.00034350175721773666\n"
     ]
    }
   ],
   "source": [
    "print('MAE', mean_absolute_error(y_validation, y_pred_lr))\n",
    "print('MSE', mean_squared_error(y_validation, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-offset",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-guard",
   "metadata": {},
   "source": [
    "I then chose to tune a random forest again using a random search cross validation as it is faster than a grid search while still finding optimal hyperparameters for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "quantitative-updating",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  65 out of  65 | elapsed:   17.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(transformers=[('categorical',\n",
       "                                                  Pipeline(steps=[('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore')),\n",
       "                                                                  ('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                                 strategy='most_frequent'))]),\n",
       "                                                  ['NCAA_CONFERENCE',\n",
       "                                                   'SCHOOL_TYPE',\n",
       "                                                   'NCAA_SUBDIVISION',\n",
       "                                                   'SPORT_CODE',\n",
       "                                                   'NCAA_DIVISION']),\n",
       "                                                 ('continuous',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   MinMaxScale...\n",
       "                                                                          'sqrt',\n",
       "                                                                          'log2'],\n",
       "                                                         'max_leaf_nodes': [10,\n",
       "                                                                            100,\n",
       "                                                                            1000],\n",
       "                                                         'max_samples': [None],\n",
       "                                                         'min_impurity_decrease': [0.0],\n",
       "                                                         'min_impurity_split': [None],\n",
       "                                                         'min_samples_leaf': [1,\n",
       "                                                                              10,\n",
       "                                                                              20],\n",
       "                                                         'min_samples_split': [2],\n",
       "                                                         'min_weight_fraction_leaf': [0.0],\n",
       "                                                         'n_estimators': [10,\n",
       "                                                                          100,\n",
       "                                                                          1000],\n",
       "                                                         'n_jobs': [1, -1],\n",
       "                                                         'oob_score': [False],\n",
       "                                                         'random_state': [23],\n",
       "                                                         'verbose': [0],\n",
       "                                                         'warm_start': [False,\n",
       "                                                                        True]},\n",
       "                                    verbose=1))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {'bootstrap': [True, False],\n",
    " 'ccp_alpha': [0.0],\n",
    " 'criterion': ['mse', 'gini'],\n",
    " 'max_depth': [1, 10, 100], \n",
    " 'max_features': ['auto', 'sqrt', 'log2'],\n",
    " 'max_leaf_nodes': [10, 100, 1000],\n",
    " 'max_samples': [None],\n",
    " 'min_impurity_decrease': [0.0],\n",
    " 'min_impurity_split': [None],\n",
    " 'min_samples_leaf': [1, 10, 20],\n",
    " 'min_samples_split': [2],\n",
    " 'min_weight_fraction_leaf': [0.0],\n",
    " 'n_estimators': [10, 100, 1000],\n",
    " 'n_jobs': [1, -1],\n",
    " 'oob_score': [False],\n",
    " 'random_state': [23],\n",
    " 'verbose': [0],\n",
    " 'warm_start': [False, True]}\n",
    "clf_rand = RandomizedSearchCV(estimator=RandomForestRegressor(), \n",
    "                              param_distributions=hyperparameters, \n",
    "                              n_iter=13, \n",
    "                              cv=5, \n",
    "                              verbose=1)\n",
    "\n",
    "pipe_rf_cv = Pipeline([('preprocessing',preprocessing),\n",
    "                ('clf', clf_rand)])\n",
    "pipe_rf_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-timber",
   "metadata": {},
   "source": [
    "I then get the best model that came out of the cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "retired-hydrogen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=100, max_leaf_nodes=100, min_samples_leaf=10,\n",
       "                      n_estimators=10, n_jobs=1, random_state=23,\n",
       "                      warm_start=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rand.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-chosen",
   "metadata": {},
   "source": [
    "I then wanted to display the hyperparameters that were chosen out of the cross validation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "suffering-liberty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'mse',\n",
       " 'max_depth': 100,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': 100,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 10,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 10,\n",
       " 'n_jobs': 1,\n",
       " 'oob_score': False,\n",
       " 'random_state': 23,\n",
       " 'verbose': 0,\n",
       " 'warm_start': True}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rand.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-mirror",
   "metadata": {},
   "source": [
    "I then fit this model on the data to be absolutely clear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "derived-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline([('preprocessing',preprocessing),\n",
    "                ('clf', clf_rand.best_estimator_)])\n",
    "\n",
    "y_pred_rf = pipe_rf.predict(X_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-symphony",
   "metadata": {},
   "source": [
    "I then report the metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "harmful-survey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.013480507570834327\n",
      "MSE 0.000351223403020526\n"
     ]
    }
   ],
   "source": [
    "print('MAE', mean_absolute_error(y_validation, y_pred_rf))\n",
    "print('MSE', mean_squared_error(y_validation, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-deadline",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-version",
   "metadata": {},
   "source": [
    "Our final model is the linear regression model as it slightly outperforms the random forest regressor across all displayed metrics. However, the validation metrics on these two algorithms were very close. I ultimately chose linear regression over random forests because of both the \"better\" validation metrics, and because linear models are simpler and train faster than random forests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "structural-apple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(n_jobs=-1, normalize=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_rand.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-chance",
   "metadata": {},
   "source": [
    "The parameters of the final model are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "interesting-philip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normalize': True, 'n_jobs': -1, 'fit_intercept': True, 'copy_X': True}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_rand.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-swing",
   "metadata": {},
   "source": [
    "I then wanted to explore feature importance in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "pointed-croatia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPORT_CODE 0.350 +/- 0.022\n",
      "FOURYEAR_ELIGIBILITY 0.237 +/- 0.017\n",
      "NCAA_CONFERENCE 0.070 +/- 0.008\n",
      "SCHOOL_TYPE 0.019 +/- 0.004\n",
      "FOURYEAR_ATHLETES 0.009 +/- 0.003\n",
      "NCAA_SUBDIVISION 0.005 +/- 0.003\n",
      "NCAA_DIVISION 0.001 +/- 0.000\n"
     ]
    }
   ],
   "source": [
    "def pretty_print(r):\n",
    "    for i in r.importances_mean.argsort()[::-1]:\n",
    "        print(f\"{train.columns[i]}\",\n",
    "            f\"{r.importances_mean[i]:.3f}\"\n",
    "            f\" +/- {r.importances_std[i]:.3f}\")\n",
    "\n",
    "r = permutation_importance(pipe_lr, X_validation, y_validation,\n",
    "                            n_repeats=30,\n",
    "                            random_state=0)\n",
    "pretty_print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-ferry",
   "metadata": {},
   "source": [
    "Save final model for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "preceding-palace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lin_mod']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipe_lr, 'lin_mod')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-combination",
   "metadata": {},
   "source": [
    "# Try our model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "frequent-trading",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[['SCHOOL_TYPE',\n",
    "       'SPORT_CODE', 'NCAA_DIVISION', 'NCAA_SUBDIVISION',\n",
    "       'NCAA_CONFERENCE', 'FOURYEAR_ATHLETES', \n",
    "       'FOURYEAR_ELIGIBILITY']]\n",
    "y_test = test['FOURYEAR_RETENTION']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-contest",
   "metadata": {},
   "source": [
    "# Test Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "suspected-johns",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.01363457894969726\n",
      "MSE 0.0003446653628900746\n"
     ]
    }
   ],
   "source": [
    "test_y_lr = pipe_lr.predict(X_test)\n",
    "print('MAE', mean_absolute_error(test_y_lr, y_test))\n",
    "print('MSE', mean_squared_error(test_y_lr, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-genetics",
   "metadata": {},
   "source": [
    "Since the final model preforms quite similarly on the test set as the validation set, we can assume it will generalize well. Having an MAE of ~.0136 is telling us that on average, the model is off of it's prediction of retention rate by .0136 which considering the scale is from 0 to 1 makes this model useful. This work is useful as we have not only provided a model that can predict four year retention rates, but we have also provided inference on the model. Knowing that sport code and four year eligibility are the most important features of the model gives the NCAA a place to start looking into the reasons for the recent increase in transfer rates. Future work on this model would include receiving feedback from the NCAA and collecting new features that could further improve the model, such as school's academic rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-therapist",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-portrait",
   "metadata": {},
   "source": [
    "In this project, I began with some EDA and discovered that the dataset encoded missing values with -99. I went back through the data and replaced those values with nan. However, I wanted to create a missing category in the NCAA subdivision feature as I thought the fact is was missing could be important so I replaced those values with the word 'Missing'. From there I fit 6 models with their default hyperparameters and reported their MAE and MSE so I could choose two final models to tune and fit. This returned Linear Regression and Random Forrest Regressor as my models. From there, I used a random cv search across hyperparameters to find the best model for each algorithm. I then chose linear regression as my final model as it outperformed the random forest regressor. The final model was then tested on the test data set to see if this model is generalizable and to make sure the model did not overfit to the training data. We found that the model preformed quite well on the test dataset. I finally looked at feature importance of the final model so that I could provide some model interpretation to the NCAA. I then wrote a python script for a deployment that takes a text file with the needed features and outputs a HTML file with the predicted retention rate and how that score compares to other scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-steel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
